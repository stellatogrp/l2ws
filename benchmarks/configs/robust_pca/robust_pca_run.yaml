nn_cfg:
  lr: 1e-3
  method: adam
  intermediate_layer_sizes: [500, 500]
  batch_size: 100
  epochs: 10000
  decay_lr: .6
  min_lr: 1e-7
  decay_every: 1000

plateau_decay:
  min_lr: 1e-7
  decay_factor: 5
  avg_window_size: 10 # in epochs
  tolerance: 1e-4
  patience: 2

pretrain:
  pretrain_method: adam
  pretrain_stepsize: 1e-4
  pretrain_iters: 0
  pretrain_batches: 10

data:
  datetime: ''

train_unrolls: 20
eval_unrolls: 500
eval_every_x_epochs: 10
save_every_x_epochs: 1
write_csv_every_x_batches: 1
N_train: 1000
N_test: 20
num_samples: 100
prediction_variable: w
supervised: False
angle_anchors: [0]
dx: 0
dy: 0
tx: 50
ty: 50
learn_XY: False
loss_method: constant_sum
#increasing_sum or constant_sum or fixed_k 
plot_iterates: [0, 10, 20]
share_all: False
num_clusters: 100
pretrain_alpha: False
normalize_inputs: True
normalize_alpha: 'other'
epochs_jit: 10
