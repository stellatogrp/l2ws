{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajivs/Documents/Princeton/l2ws_conic/env/lib/python3.9/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Now you can import the module from the examples directory\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import vmap\n",
    "from functools import partial\n",
    "from scipy.spatial import distance_matrix\n",
    "from l2ws.utils.nn_utils import get_nearest_neighbors\n",
    "from l2ws.l2ws_model import L2WSmodel\n",
    "from l2ws.algo_steps import create_k_steps_train, create_k_steps_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected gradient descent\n",
    "\n",
    "In this tutorial we show how to use our package to learn high-quality warm starts for your favorite fixed-point algorithm.\n",
    "We consider projected gradient descent to solve the problem\n",
    "\n",
    "\\begin{array}{ll} \\rm{minimize} &f_\\theta(z),\n",
    "&\\\\ \\quad z \\in \\mathcal{C}\n",
    " \\end{array}\n",
    "where $z \\in \\mathbf{R}^n$ is the decision variable, $f_\\theta : \\mathbf{R}^n \\rightarrow \\mathbf{R}$ is a convex function and $L$-smooth function.\n",
    "\n",
    "The iterates of projected gradient descent are\n",
    "\\begin{equation}\n",
    "    z^{i+1} = \\Pi_{\\mathcal{C}}(z^i - \\alpha \\nabla f_\\theta(z^i)).\n",
    "\\end{equation}\n",
    "\n",
    "We take the specific example of non-negative least squares\n",
    "\n",
    "\\begin{array}{ll} \\rm{minimize} &\\|Az-b\\|_2^2,\n",
    "&\\\\ \\quad z \\geq 0\n",
    " \\end{array}\n",
    "where $A \\in \\mathbf{R}^{m \\times n}$ and $b \\in \\mathbf{R}^{m}$ are problem data.\n",
    "Here, $\\theta = b$ is the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "N_train = 5000\n",
    "N_test = 100\n",
    "N = N_train + N_test\n",
    "m, n = 50, 25\n",
    "\n",
    "# generate a single random A matrix\n",
    "A = jnp.array(np.random.normal(size=(m, n)))\n",
    "\n",
    "# generate N different b vectors\n",
    "b_mat = jnp.array(np.random.normal(size=(N, m)))\n",
    "\n",
    "k = 500\n",
    "z0 = jnp.zeros(n)\n",
    "evals, evecs = jnp.linalg.eigh(A.T @ A)\n",
    "step = 1 / jnp.max(evals)\n",
    "\n",
    "# setup inputs\n",
    "b_mat_train = b_mat[:N_train, :]\n",
    "b_mat_test = b_mat[N_train:, :]\n",
    "train_inputs = b_mat_train\n",
    "test_inputs = b_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code up the fixed-point algorithm\n",
    "def proj_gd_fixed_point(z, theta):\n",
    "    return jnp.clip(z - step * A.T @ (A @ z - theta), a_min=0)\n",
    "\n",
    "k_steps_train_proj_gd = create_k_steps_train(proj_gd_fixed_point)\n",
    "k_steps_eval_proj_gd = create_k_steps_eval(proj_gd_fixed_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve all of the problems to get z_stars_train and z_stars_test\n",
    "batch_k_steps_train_proj_gd = vmap(k_steps_train_proj_gd, in_axes=(None, 0, 0, None, None, None), out_axes=(0, 0))\n",
    "\n",
    "z0_init_mat = jnp.zeros((N, n))\n",
    "z_finals, iter_losses = batch_k_steps_train_proj_gd(1000, z0_init_mat, b_mat, False, None, False)\n",
    "\n",
    "z_stars_train = z_finals[:N_train, :]\n",
    "z_stars_test = z_finals[N_train:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ProjGDmodel object that inherits from the L2WSmodel\n",
    "class ProjGDmodel(L2WSmodel):\n",
    "    def __init__(self, input_dict):\n",
    "        # self.fista = input_dict['algorithm'] == 'fista'\n",
    "        super(ProjGDmodel, self).__init__(input_dict)\n",
    "\n",
    "    def initialize_algo(self, input_dict):\n",
    "        self.factor_static = None\n",
    "        self.algo = 'proj_gd'\n",
    "        self.factors_required = False\n",
    "        self.q_mat_train, self.q_mat_test = input_dict['b_mat_train'], input_dict['b_mat_test']\n",
    "        self.output_size = n\n",
    "\n",
    "        self.k_steps_train_fn = partial(k_steps_train_proj_gd, jit=self.jit)\n",
    "        self.k_steps_eval_fn = partial(k_steps_eval_proj_gd, jit=self.jit)\n",
    "        self.out_axes_length = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create l2ws_model\n",
    "nn_cfg = {'lr': 1e-3, 'method': 'adam', 'intermediate_layer_sizes': [100]}\n",
    "train_unrolls = 15\n",
    "supervised = False\n",
    "input_dict = dict(algorithm='proj_gd',\n",
    "                    supervised=supervised,\n",
    "                    train_unrolls=train_unrolls, \n",
    "                    jit=True,\n",
    "                    train_inputs=train_inputs, \n",
    "                    test_inputs=test_inputs,\n",
    "                    b_mat_train=b_mat_train, \n",
    "                    b_mat_test=b_mat_test,\n",
    "                    nn_cfg=nn_cfg,\n",
    "                    z_stars_train=z_stars_train,\n",
    "                    z_stars_test=z_stars_test,\n",
    "                    )\n",
    "proj_gd_model = ProjGDmodel(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cold start evaluation\n",
    "k = 100\n",
    "init_eval_out = proj_gd_model.evaluate(\n",
    "    k, test_inputs, b_mat_test, z_stars=z_stars_test, fixed_ws=False, tag='test')\n",
    "init_test_losses = init_eval_out[1][1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances [[ 9.93193168  9.62785156 10.80164922 ...  8.32819901  9.53913757\n",
      "   9.49720965]\n",
      " [10.58304128 11.44594845 13.22317106 ... 10.62330622 12.38117561\n",
      "  10.03758508]\n",
      " [11.47430542 12.75321912 10.27950395 ...  9.84002225  9.84028938\n",
      "   9.76634099]\n",
      " ...\n",
      " [10.76189671 10.00784086 10.20048707 ...  9.05181563 10.26836854\n",
      "   8.56355041]\n",
      " [10.206239   10.71995581 11.01504408 ...  9.36942741  9.69739709\n",
      "  10.52457185]\n",
      " [10.15974531 10.70140221 12.30301967 ...  7.97272642 11.06015278\n",
      "   9.45495608]]\n",
      "indices [ 922  845  653 2952 2498 2289 4340 2280 2019 3901 4635 3045 4231 2953\n",
      "  539  381  360 3344 3927 1520 4415 1563 3854 3332 3498 2692 1179 1556\n",
      " 1126 1378 1207 1363 2474 4749 3121 2847  629 3515 3251 4452 4255 2134\n",
      " 4433 4784 3231  728 4564 3212 1218 3324 1956 1390 1759 4521  160 3850\n",
      " 3341 4061 2825 4415 1032  406 4870 4659 4808 1179  817 4932 4954 2871\n",
      "  470  806 3635 4416 2956 4438 4934 2324 1422 4755 2166 1123 3948 3414\n",
      " 2996  645 4403  595 4954  862 2825 3231  756 2564 3028  293 4752  513\n",
      " 3548  165]\n",
      "best val [6.29971896 7.54687511 7.17505888 7.0730612  6.6476068  7.28783044\n",
      " 7.02092784 6.72305833 6.0993526  7.66205449 7.37142104 7.00581568\n",
      " 7.78284066 6.44915596 7.4300042  7.63079779 7.48496936 7.36771237\n",
      " 6.6448044  6.74263057 7.68426121 6.79328381 7.91376381 6.20588044\n",
      " 6.94110809 6.68260824 6.92487652 6.94643553 7.02699954 6.39805673\n",
      " 7.09690913 7.39807736 6.12176945 7.25846037 7.13211735 5.94753868\n",
      " 6.49396308 7.343807   6.76472987 6.64411706 6.32356988 6.27602853\n",
      " 6.77055506 6.94520861 7.26666086 6.81453275 7.74762027 7.03820772\n",
      " 6.61163394 6.70382905 7.01274912 6.21418899 7.27975127 6.37455029\n",
      " 6.50738246 6.49736074 6.72749048 6.85181018 6.53093165 7.42422397\n",
      " 6.05121206 7.23871765 6.57825328 6.5877527  7.6556834  6.59664015\n",
      " 6.09762229 6.98576983 6.50047907 6.62431767 7.23538442 6.10160836\n",
      " 6.99414467 6.91627661 6.19156723 8.28623734 6.35175646 7.25681705\n",
      " 5.96242236 7.27473971 7.84276997 6.40012361 6.60075315 6.5844065\n",
      " 6.34748251 6.93819908 7.48725595 8.00398014 6.68188391 7.22217882\n",
      " 7.39496211 6.44400925 6.04173418 6.93426734 6.36287309 6.25198355\n",
      " 6.69503292 6.35996525 7.0260493  7.45520051]\n"
     ]
    }
   ],
   "source": [
    "# nearest neighbor\n",
    "# train_inputs, test_inputs = theta_mat_train, theta_mat_test\n",
    "\n",
    "# full evaluation on the test set with nearest neighbor\n",
    "\n",
    "nearest_neighbors_z = get_nearest_neighbors(train_inputs, test_inputs, z_stars_train)\n",
    "nn_eval_out = proj_gd_model.evaluate(k, nearest_neighbors_z,\n",
    "                                    b_mat_test, z_stars=z_stars_test,\n",
    "                                    fixed_ws=True, tag='test')\n",
    "nn_losses = nn_eval_out[1][1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the osqp_model\n",
    "# call train_batch without jitting\n",
    "params, state = proj_gd_model.params, proj_gd_model.state\n",
    "num_epochs = 1000\n",
    "train_losses = jnp.zeros(num_epochs)\n",
    "for i in range(num_epochs):\n",
    "    train_result = proj_gd_model.train_full_batch(params, state)\n",
    "    loss, params, state = train_result\n",
    "    train_losses = train_losses.at[i].set(loss)\n",
    "\n",
    "proj_gd_model.params, proj_gd_model.state = params, state\n",
    "\n",
    "# full evaluation on the test set\n",
    "final_eval_out = proj_gd_model.evaluate(\n",
    "    k, test_inputs, b_mat_test, z_stars=z_stars_test, fixed_ws=False, tag='test')\n",
    "final_test_losses = final_eval_out[1][1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColormapRegistry' object has no attribute 'set1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m colors \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mcolormaps\u001b[39m.\u001b[39;49mset1\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(final_test_losses, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlearned k=\u001b[39m\u001b[39m{\u001b[39;00mtrain_unrolls\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(nn_losses, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest neighbor\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ColormapRegistry' object has no attribute 'set1'"
     ]
    }
   ],
   "source": [
    "colors = plt.cm.Set1\n",
    "\n",
    "plt.plot(final_test_losses, label=f\"learned k={train_unrolls}\")\n",
    "plt.plot(nn_losses, label='nearest neighbor')\n",
    "plt.plot(init_test_losses, label='cold start')\n",
    "plt.yscale('log')\n",
    "plt.title('fixed-point residuals')\n",
    "plt.ylabel('test fixed-point residuals')\n",
    "plt.xlabel('evaluation iterations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(init_test_losses / final_test_losses, label=f\"learned k={train_unrolls}\")\n",
    "plt.plot(init_test_losses / nn_losses, label='nearest neighbor')\n",
    "plt.title('gains')\n",
    "plt.ylabel('test gain over the cold start')\n",
    "plt.xlabel('evaluation iterations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "label=r'train loss: $\\ell^{\\rm reg}_\\theta$ in this case' if supervised else r'train loss: $\\ell^{\\rm fp}_\\theta$ in this case'\n",
    "plt.plot(train_losses, label=label, color='magenta')\n",
    "plt.yscale('log')\n",
    "test_losses = np.array([init_test_losses[train_unrolls], final_test_losses[train_unrolls]])\n",
    "epochs_array = np.array([0, num_epochs])\n",
    "\n",
    "test_label = r'test fixed-point residual: $\\ell^{\\rm fp}_\\theta$'\n",
    "plt.plot(epochs_array, test_losses, label=test_label, color='brown')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.yscale('log')\n",
    "plt.title('training and test losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21db7f3255ac07e1babca6bbfc6c212cf18fd46cf53c71314c82ee89f20e77b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
