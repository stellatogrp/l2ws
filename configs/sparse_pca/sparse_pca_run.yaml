nn_cfg:
  lr: 1e-3
  method: adam
  intermediate_layer_sizes: [500, 500]
  batch_size: 100
  epochs: 1e6
  decay_lr: .1
  min_lr: 1e-7
  decay_every: 1e7

plateau_decay:
  min_lr: 1e-7
  decay_factor: 5
  avg_window_size: 5 # in epochs
  tolerance: 1e-3
  patience: 50


pretrain:
  pretrain_method: adam
  pretrain_stepsize: 1e-3
  pretrain_iters: 0
  pretrain_batches: 10

data:
  datetime: '' #'2023-04-10/11-17-04'


eval_unrolls: 500
eval_every_x_epochs: 10
save_every_x_epochs: 1
test_every_x_epochs: 1
write_csv_every_x_batches: 1
epochs_jit: 2
N_train: 10000
N_test: 1000
# num_samples: 1000
prediction_variable: w
angle_anchors: [0]
plot_iterates: [0, 10, 20]
loss_method: 'fixed_k' #'fixed_k' #'constant_sum'
share_all: False
num_clusters: 100
pretrain_alpha: False
normalize_inputs: True
normalize_alpha: 'other'

accuracies: [1, .1, .01, .001, .0001]
rho_x: 1
scale: 1
alpha_relax: 1
skip_startup: True
# solve_c_num: 1000
save_weights_flag: True

load_weights_datetime: '2023-07-26/21-18-04'
train_unrolls: 60
supervised: True
num_samples: 100
# num_samples_test: 1000
# num_samples_train: 100
# eval_batch_size_test: 200
# eval_batch_size_train: 200
# num_samples: 10
# lightweight: True

# output_datetimes: ['2023-07-25/23-28-42', '2023-07-25/22-13-13', '2023-07-26/22-08-40', '2023-07-26/22-38-49', '2023-07-26/22-47-30',
# '2023-07-26/21-55-00', '2023-07-26/08-49-43', '2023-07-26/21-24-25', '2023-07-26/20-47-36', '2023-07-26/21-18-04']




















# below is old
# obj: ['2023-06-05/10-59-27', '2023-06-04/22-30-33', '2023-06-04/21-53-52', '2023-06-04/21-50-00', '2023-06-04/22-23-46', 
# reg: '2023-06-14/23-19-14', '2023-06-14/23-50-40', '2023-06-14/23-25-13', '2023-07-11/16-25-13', '2023-07-11/18-59-59']