nn_cfg:
  lr: 1e-4
  method: adam
  intermediate_layer_sizes: [500, 500]
  batch_size: 100
  epochs: 1e6
  decay_lr: .1
  min_lr: 1e-7
  decay_every: 1e7

plateau_decay:
  min_lr: 1e-7
  decay_factor: 5
  avg_window_size: 5 # in epochs
  tolerance: 1e-8 #1e-3
  patience: 1


pretrain:
  pretrain_method: adam
  pretrain_stepsize: 1e-3
  pretrain_iters: 0
  pretrain_batches: 10

data:
  datetime: ''

<<<<<<< HEAD
# eval_batch_size: 100
train_unrolls: 15
=======
eval_batch_size: 100
train_unrolls: 10
>>>>>>> df0f5a9c31b06341f93e4b38f32c889a241efcf4
eval_unrolls: 1000
eval_every_x_epochs: 200
save_every_x_epochs: 1
test_every_x_epochs: 1
write_csv_every_x_batches: 1
epochs_jit: 10
<<<<<<< HEAD
N_train: 10000
N_test: 1000
num_samples: 100
=======
N_train: 1000
N_test: 20
num_samples: 10
>>>>>>> df0f5a9c31b06341f93e4b38f32c889a241efcf4
prediction_variable: w
angle_anchors: [0]
supervised: True
plot_iterates: [0, 10, 20]
loss_method: 'fixed_k' #'fixed_k' #'constant_sum'
# share_all: False
num_clusters: 10
pretrain_alpha: False
normalize_inputs: False
normalize_alpha: 'other'

accuracies: [.1, .01, .001, .0001]
rho_x: 1
scale: 1
alpha_relax: 1
skip_startup: False
save_weights_flag: True
# load_weights_datetime: '2023-07-16/15-58-19'
# load_weights_datetime: '2023-07-08/21-14-58'

# solving in C
# rel_tols: [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]
# abs_tols: [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]
# solve_c_num: 10

# rollouts
# num_rollouts: 0
# closed_loop_budget: 10

# visualize
iterates_visualize: [10, 20, 50, 90] #[10, 20, 50, 100, 200, 500]